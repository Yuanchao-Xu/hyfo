frc[rain[-extrapolateIndex]] <- quantile(obs[which(obs > prThreshold & !is.na(obs))],
probs = ecdfHindcast(frc[rain[-extrapolateIndex]]),
na.rm = TRUE, type = 4)
} else {
frc[rain] <- quantile(obs[which(obs > prThreshold & !is.na(obs))],
probs = ecdfHindcast(frc[rain]), na.rm = TRUE, type = 4)
}
} else {
frc[rain] <- quantile(obs[which(obs > prThreshold & !is.na(obs))],
probs = ecdfHindcast(frc[rain]), na.rm = TRUE, type = 4)
}
}
if (length(drizzle) > 0){
# drizzle part is a seperate part. it use the ecdf of frc (larger than minHindcastPreci) to
# biascorrect the original drizzle part
frc[drizzle] <- quantile(frc[which(frc > min(hindcast[which(hindcast > minHindcastPreci)], na.rm = TRUE) &
!is.na(frc))], probs = ecdfFrc(frc[drizzle]), na.rm = TRUE,
type = 4)
}
frc[noRain] <- 0
} else {
# in this condition minHindcastPreci is the max of hindcast, so all hindcast <= minHindcastPreci
# And frc distribution is used then.
noRain <- which(frc <= minHindcastPreci & !is.na(frc))
rain <- which(frc > minHindcastPreci & !is.na(frc))
if (length(rain) > 0) {
ecdfFrc <- ecdf(frc[rain])
frc[rain] <- quantile(obs[which(obs > prThreshold & !is.na(obs))], probs = ecdfFrc(frc[rain]),
na.rm = TRUE, type = 4)
}
frc[noRain]<-0
}
}
}
} else if (method == 'gqm') {
# this condition I don't know why there should be some value hindcast <= threshold
if (any(hindcast <= prThreshold)) {
ind <- which(obs > prThreshold & !is.na(obs))
obsGamma <- fitdistr(obs[ind],"gamma")
ind <- which(hindcast > 0 & !is.na(hindcast))
hindcastGamma <- fitdistr(hindcast[ind],"gamma")
rain <- which(frc > minHindcastPreci & !is.na(frc))
noRain <- which(frc <= minHindcastPreci & !is.na(frc))
probF <- pgamma(frc[rain], hindcastGamma$estimate[1], rate = hindcastGamma$estimate[2])
frc[rain] <- qgamma(probF,obsGamma$estimate[1], rate = obsGamma$estimate[2])
frc[noRain] <- 0
}
}
return(frc)
}
frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = T, prThreshold = 1)
debug(biasCorrect_core)
frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = T, prThreshold = 1)
lowerIndex
frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = T, prThreshold = 0)
lowerIndex
index
minHindcastPreci
higherIndex
higherIndex
lowerIndex
obs_sorted[(lowerIndex + 1):higherIndex]
higherIndex
mean(obs_sorted[(lowerIndex + 1):higherIndex],
na.rm = TRUE)
mean(hindcast_sorted[(lowerIndex + 1):higherIndex], na.rm = T)
obs_sorted[(lowerIndex + 1):higherIndex]
hindcast_sorted[(lowerIndex + 1):higherIndex]
frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = T, prThreshold = 1)
q
frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = T, prThreshold = 0)
N
N
lowerIndex
higherIndex
prThreshold
obs_sorted[(lowerIndex + 1):higherIndex])
obs_sorted[(lowerIndex + 1):higherIndex]
mean(obs_sorted[(lowerIndex + 1):higherIndex],
na.rm = TRUE)
hindcast_sorted[(lowerIndex + 1):higherIndex]
hindcast_sorted[(lowerIndex + 1):higherIndex]
frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = T, prThreshold = 1)
minHindcastPreci
min(obs(obs>0))
min(obs(obs>0))
min(obs(obs>0))
min(obs)
min(obs[obs>0])
frc <- datalist[[3]]
obs <- datalist[[2]]
hindcast <- datalist[[3]]
frc[frc>0]
min(frc[frc>0])
min(hindcast[hindcast>0])
hindcast <- datalist[[1]]
min(hindcast[hindcast>0])
min(hindcast[hindcast>0], na.rm = T)
frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = T, prThreshold = 1)
lowerIndex
minHindcastPreci
higherIndex
lowerIndex
mean(obs_sorted[(lowerIndex + 1):higherIndex],
na.rm = TRUE)
hindcast_sorted[(lowerIndex + 1):higherIndex]
obs_sorted[(lowerIndex + 1):higherIndex]
plot(hindcast_sorted)
plot(hindcast_sorted, add = T, col = 'red')
min(obs[obs > 0])
min(obs[obs > 0.09])
min(obs[obs > 1])
min(obs[obs > 1.08])
frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = T, prThreshold = 0)
lowerIndex
minHindcastPreci
higherIndex
higherIndex
unique(obs_sorted[(lowerIndex + 1):higherIndex])
mean(obs_sorted[(lowerIndex + 1):higherIndex],
na.rm = TRUE)
lowerIndex
higherIndex
obs_sorted[(lowerIndex + 1):higherIndex]
hindcast_sorted[(lowerIndex + 1):higherIndex]
#' Biascorrect the input timeseries or hyfo dataset
#'
#' Biascorrect the input time series or dataset, the input time series or dataset should consist of observation, hindcast, and forecast.
#' observation and hindcast should belong to the same period, in order to calibrate. Then the modified forecast
#' will be returned. If the input is a time series, first column should be date column and rest columns should be
#' the value column. If the input is a hyfo dataset, the dataset should be the result of \code{loadNcdf}, or a list
#' file with the same format.
#'
#' @param frc a hyfo grid data output or a dataframe (time series) consists of Date column and one or more value columns,
#' representing the forecast to be calibrated.
#' @param hindcast a hyfo grid data output or a dataframe(time series) consists of Date column and one or more value columns,
#' representing the hindcast data. This data will be used in the calibration of the forecast, so it's better to have the same date period as
#' observation data. Check details for more information.
#' @param obs a hyfo grid data output or a dataframe (time series) consists of Date column and one or more value columns,
#' representing the observation data.
#' @param method bias correct method, including 'delta', 'scaling'...
#' @param scaleType only when the method "scaling" is chosen, scaleType will be available. Two different types
#' of scaling method, 'add' and 'mult', which means additive and multiplicative scaling method. More info check
#' details.
#' @param input If input is a time series, \code{input = 'TS'} needs to be assigned, or hyfo will take it as
#' an hyfo output grid file. Default is hyfo output grid file, where in most of the cases we prefer.
#' @param preci If the precipitation is biascorrected, then you have to assign \code{preci = TRUE}. Since for
#' precipitation, some biascorrect methods may not apply to, or some methods are specially for precipitation.
#' Default is FALSE, refer to details.
#' @param prThreshold The minimum value that is considered as a non-zero precipitation. Default to 1 (assuming mm).
#' @param extrapolate When use 'eqm' method, and 'no' is set, modified frc is bounded by the range of obs.
#' If 'constant' is set, modified frc is not bounded by the range of obs.
#' @details
#'
#' Since climate forecast is based on global condition, when downscaling to different regions, it may include
#' some bias, biascorrection is used then to fix the bias.
#'
#' \strong{Hindcast}
#'
#' In order to bias correct, we need to pick up some
#' data from the forecast to train with the observation, which is called hindcast in this function. Hindcast
#' should have \strong{EVERY} attributes that forecast has.
#'
#' Hindcast is also called re-forecast, is the forecast of the past. E.g. you have a forecast from year 2000-2010, assuming now you are in 2005. So from 2000-2005, this period
#' is the hindcast period, and 2005-2010, this period is the forecast period.
#'
#' Hindcast can be the same as forecast, i.e., you can use forecast itself as hindcast to train the bias correction.
#'
#'
#' \strong{How it works}
#'
#' Forecast product has to be calibrated, usually the system is doing forecast in real time. So, e.g., if the
#' forecast starts from year 2000, assuming you are in year 2003, then you will have 3 years' hindcast
#' data (year 2000 - 2003), which can be used to calibrate. And your forecast period is (2003-2004)
#'
#' E.g. you have observation from 2001 - 2002, this is your input obs. Then you can take the same
#' period (2001-2002) from the forecast, which is the hindcast period. For forecast, you can take any period.
#' The program will evaluate the obs and hindcast, to get the modification of the forecast, and then add the
#' modification to the forecast data.
#'
#' \strong{method}
#'
#' Different methods used in the bias correction.
#'
#' \strong{delta}
#'
#' This method consists on adding to the observations the mean change signal (delta method).
#' This method is applicable to any kind of variable but it is preferable to avoid it for bounded variables
#'  (e.g. precipitation, wind speed, etc.) because values out of the variable range could be obtained
#'  (e.g. negative wind speeds...)
#'
#'  \strong{scaling}
#'
#' This method consists on scaling the simulation  with the difference (additive) or quotient (multiplicative)
#' between the observed and simulated means in the train period. The \code{additive} or \code{multiplicative}
#' correction is defined by parameter \code{scaling.type} (default is \code{additive}).
#' The additive version is preferably applicable to unbounded variables (e.g. temperature)
#' and the multiplicative to variables with a lower bound (e.g. precipitation, because it also preserves the frequency).
#'
#'  \strong{eqm}
#' Can keep the extreme value, if you choose constant extrapolation method. But then you will face the risk
#' that the extreme value is an error.
#'
#'  \strong{gqm}
#' Can somehow filter some extreme values caused by errors, while keep the extreme value. Seems more reasonable.
#' Better have a long period of training, and the if the forecast system is relatively stable.
#'
#' @examples
#'
#' # Use testdl as an example, we take frc, hindcast and obs from testdl.
#' data(testdl)
#'
#' # common period has to be extracted in order to better train the forecast.
#'
#' datalist <- extractPeriod(testdl, startDate = '1994-1-1', endDate = '1995-10-1')
#'
#' frc <- datalist[[1]]
#' hindcast <- datalist[[2]]
#' obs <- datalist[[3]]
#'
#' # default method is delta
#' frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS')
#' # for precipitation data, extra process needs to be executed, so you have to tell
#' # the program to it is a precipitation data.
#'
#' frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = TRUE)
#'
#' # You can use other methods to biascorrect.
#' frc_new <- biasCorrect(frc, hindcast, obs, method = 'scaling', scaleType = 'multi', input = 'TS')
#'
#' frc_new <- biasCorrect(frc, hindcast, obs, method = 'eqm', input = 'TS', preci = TRUE)
#' frc_new <- biasCorrect(frc, hindcast, obs, method = 'gqm', input = 'TS', preci = TRUE)
#'
#' # If the forecasts you extracted only has incontinuous data for certain months and years, e.g.,
#' # for seasonal forecasting, forecasts only provide 3-6 months data, so the case can be
#' # for example Dec, Jan and Feb of every year from year 1999-2005.
#' # In such case, you need to extract certain months and years from observed time series.
#' # extractPeriod() can be then used.
#'
#' # More examples can be found in the user manual on http://yuanchao-xu.github.io/hyfo/
#'
#'
#' @references
#' Bias correction methods come from \code{biasCorrection} from \code{dowscaleR}
#'
#' Santander Meteorology Group (2015). downscaleR: Climate data manipulation and statistical downscaling. R
#' package version 0.6-0. https://github.com/SantanderMetGroup/downscaleR/wiki
#' @export
biasCorrect <- function(frc, hindcast, obs, method = 'delta', scaleType = 'multi', input = 'hyfo',
preci = FALSE, prThreshold = 0, extrapolate = 'constant'){
if (input == 'TS') {
# First check if the first column is Date
if (!grepl('-|/', obs[1, 1]) | !grepl('-|/', hindcast[1, 1]) | !grepl('-|/', frc[1, 1])) {
stop('First column is not date or Wrong Date formate, check the format in ?as.Date{base}
and use as.Date to convert.If your input is a hyfo dataset, put input = "hyfo" as an
argument, check help for more info.')
}
# change to date type is easier, but in case in future the flood part is added, Date type doesn't have
# hour, min and sec, so, it's better to convert it into POSIxlt.
# if condition only accepts one condition, for list comparison, there are a lot of conditions, better
# further process it, like using any.
if (any(as.POSIXlt(hindcast[, 1]) != as.POSIXlt(obs[, 1]))) {
warning('time of obs and time of hindcast are not the same, which may cause inaccuracy in
the calibration.')
}
if (ncol(frc) == 2) {
frc_data <- biasCorrect_core(frc[, 2], hindcast[, 2], obs[, 2], method = method,
scaleType = scaleType, preci = preci, prThreshold = prThreshold)
} else if (ncol(frc) > 2) {
# In this case more than one value columns exist in the dataset, both frc and hindcast.
n <- ncol(frc)
# For every column, it's biascorrected respectively.
frc_data <- lapply(2:n, function(x) biasCorrect_core(frc[, x], hindcast[, x], obs[, 2], method = method,
scaleType = scaleType, preci = preci,
prThreshold = prThreshold))
frc_data <- do.call('cbind', frc_data)
} else stop('Wrong TS input, check your TS dimension.')
} else if (input == 'hyfo') {
print('Under development...')
}
names <- colnames(frc)
frc <- data.frame(frc[, 1], frc_data)
colnames(frc) <- names
return(frc)
}
#' @importFrom MASS fitdistr
#' @importFrom stats ecdf quantile pgamma qgamma rgamma
#'
#' @references
#' Bias correction methods come from \code{biasCorrection} from \code{dowscaleR}
#'
#' Santander Meteorology Group (2015). downscaleR: Climate data manipulation and statistical downscaling. R
#' package version 0.6-0. https://github.com/SantanderMetGroup/downscaleR/wiki
# this is only used to calculate the value column,
biasCorrect_core <- function(frc, hindcast, obs, method = 'delta', scaleType = 'multi',
preci = FALSE, prThreshold = 0, extrapolate = 'constant'){
# If the variable is precipitation, some further process needs to be added.
# The process is taken from downscaleR, to provide a more reasonable hindcast, used in the calibration.
if (preci == TRUE) {
# lowerIndex is based on obs
lowerIndex <- length(which(obs < prThreshold))
# In the original function, this minHindcastPreci is Pth[,i,j] in downscaleR, and it is originally
# set to NA, which is not so appropriate for all the precipitations.
# In the original function, there are only two conditions, 1. all the obs less than threshold
# 2. there are some obs less than threshold.
# While, if we set threshold to 0, there could be a 3rd condition, all the obs no less than threshold.
# Here I set this situation, firstly set minHindcastPreci to the min of the hindcast. Because in future
# use, 'eqm' method is going to use this value.
#set this minHindcastPreci <- min(hindcast, na.rm = TRUE) or change the following condition
# to lowerIndex >= 0.
if (lowerIndex >= 0 & lowerIndex < length(obs)) {
index <- sort(hindcast, decreasing = FALSE, na.last = NA, index.return = TRUE)$ix
hindcast_sorted <- sort(hindcast, decreasing = FALSE, na.last = NA)
# minHindcastPreci is the min preci over threshold FOR ***HINDCAST***
# But use obs to get the lowerIndex, so obs[lowerIndex + 1] > prThreshold, but
# hindcast_sorted[lowerIndex + 1] may greater than or smaller than ptThreshold
# It would be better to understand if you draw two lines: hindcast_sorted and obs_sorted
# with y = prThreshold, you will find the difference of the two.
# In principle, the value under the threshold needs to be replaced by some other reasonable value.
# simplest way
minHindcastPreci <- hindcast_sorted[lowerIndex + 1]
# Also here if minHindcastPreci is 0 and prThreshold is 0, will cause problem, bettter set
# I set it prThreshold != 0
if (minHindcastPreci <= prThreshold & prThreshold != 0) {
obs_sorted <- sort(obs, decreasing = FALSE, na.last = NA)
# higherIndex is based on hindcast
higherIndex <- which(hindcast_sorted > prThreshold & !is.na(hindcast_sorted))
if (length(higherIndex) == 0) {
higherIndex <- max(which(!is.na(hindcast_sorted)))
higherIndex <- min(length(obs_sorted), higherIndex)
} else {
higherIndex <- min(higherIndex)
}
# here I don't know why choose 6.
# Written # [Shape parameter Scale parameter] in original package
if (length(unique(obs_sorted[(lowerIndex + 1):higherIndex])) < 6) {
hindcast_sorted[(lowerIndex + 1):higherIndex] <- mean(obs_sorted[(lowerIndex + 1):higherIndex],
na.rm = TRUE)
} else {
obsGamma <- fitdistr(obs_sorted[(lowerIndex + 1):higherIndex], "gamma")
# this is to replace the original hindcast value between lowerIndex and higherIndex with
# some value taken from gamma distribution just generated.
hindcast_sorted[(lowerIndex + 1):higherIndex] <- rgamma(higherIndex - lowerIndex, obsGamma$estimate[1],
rate = obsGamma$estimate[2])
}
hindcast_sorted <- sort(hindcast_sorted, decreasing = FALSE, na.last = NA)
}
minIndex <- min(lowerIndex, length(hindcast))
hindcast_sorted[1:minIndex] <- 0
hindcast[index] <- hindcast_sorted
} else if (lowerIndex == length(obs)) {
index <- sort(hindcast, decreasing = FALSE, na.last = NA, index.return = TRUE)$ix
hindcast_sorted <- sort(hindcast, decreasing = FALSE, na.last = NA)
minHindcastPreci <- hindcast_sorted[lowerIndex]
# here is to compare with hindcast, not obs
minIndex <- min(lowerIndex, length(hindcast))
hindcas_sortedt[1:minIndex] <- 0
hindcast[index] <- hindcast_sorted
}
}
# default is the simplest method in biascorrection, just do simple addition and subtraction.
if (method == 'delta') {
# comes from downscaleR biascorrection method
frcMean <- mean(obs, na.rm = TRUE)
hindcastMean <- mean(hindcast, na.rm = TRUE)
frc <- obs - hindcastMean + frcMean
} else if (method == 'scaling') {
obsMean <- mean(obs, na.rm = TRUE)
hindcastMean <- mean(hindcast, na.rm = TRUE)
if (scaleType == 'multi') {
frc <- frc / hindcastMean * obsMean
} else if (scaleType == 'add') {
frc <- frc - hindcastMean + obsMean
}
} else if (method == 'eqm') {
# In this method, the value is bounded by the observation
if (preci == FALSE) {
if (any(!is.na(hindcast)) & any(!is.na(obs))) {
ecdfHindcast <- ecdf(hindcast)
if (extrapolate == 'constant') {
higherIndex <- which(frc > max(hindcast, na.rm = TRUE))
lowerIndex <- which(frc < min(hindcast, na.rm = TRUE))
extrapolateIndex <- c(higherIndex, lowerIndex)
if (length(higherIndex) > 0) {
maxHindcast <- max(hindcast, na.rm = TRUE)
dif <- maxHindcast - max(obs, na.rm = TRUE)
frc[higherIndex] <- frc[higherIndex] - dif
}
if (length(lowerIndex) > 0) {
minHindcast <- min(hindcast, na.rm = TRUE)
dif <- minHindcast - min(obs, nna.rm = TRUE)
frc[lowerIndex] <- frc[lowerIndex] - dif
}
frc[-extrapolateIndex] <- quantile(obs, probs = ecdfHindcast(frc[-extrapolateIndex]),
na.rm = TRUE, type = 4)
} else {
frc <- quantile(obs, probs = ecdfHindcast(frc), na.rm = TRUE, type = 4)
}
}
} else {
if (any(!is.na(hindcast)) & any(!is.na(obs))) {
# Most of time this condition seems useless because minHindcastPreci comes from hindcast, so there will be
# always hindcast > minHindcastPreci exists.
# Unless one condition that minHindcastPreci is the max in the hindcast, than on hindcast > minHindcastPreci
if (length(which(hindcast > minHindcastPreci)) > 0) {
ecdfHindcast <- ecdf(hindcast[hindcast > minHindcastPreci])
noRain <- which(frc <= minHindcastPreci & !is.na(frc))
rain <- which(frc > minHindcastPreci & !is.na(frc))
# drizzle is to see whether there are some precipitation between the min frc (over threshold) and
# min hindcast (over threshold).
drizzle <- which(frc > minHindcastPreci & frc <= min(hindcast[hindcast > minHindcastPreci], na.rm = TRUE)
& !is.na(frc))
if (length(rain) > 0) {
ecdfFrc <- ecdf(frc[rain])
if (extrapolate == 'constant') {
# This higher and lower index mean the extrapolation part
higherIndex <- which(frc[rain] > max(hindcast, na.rm = TRUE))
lowerIndex <- which(frc[rain] < min(hindcast, na.rm = TRUE))
extrapolateIndex <- c(higherIndex, lowerIndex)
if (length(higherIndex) > 0) {
maxHindcast <- max(hindcast, na.rm = TRUE)
dif <- maxHindcast - max(obs, na.rm = TRUE)
frc[rain[higherIndex]] <- frc[higherIndex] - dif
}
if (length(lowerIndex) > 0) {
minHindcast <- min(hindcast, na.rm = TRUE)
dif <- minHindcast - min(obs, nna.rm = TRUE)
frc[rain[lowerIndex]] <- frc[lowerIndex] - dif
}
# Here the original function doesn't accout for the situation that extraploateIndex is 0
# if it is 0, rain[-extraploateIndex] would be nothing
if (length(extrapolateIndex) != 0) {
frc[rain[-extrapolateIndex]] <- quantile(obs[which(obs > prThreshold & !is.na(obs))],
probs = ecdfHindcast(frc[rain[-extrapolateIndex]]),
na.rm = TRUE, type = 4)
} else {
frc[rain] <- quantile(obs[which(obs > prThreshold & !is.na(obs))],
probs = ecdfHindcast(frc[rain]), na.rm = TRUE, type = 4)
}
} else {
frc[rain] <- quantile(obs[which(obs > prThreshold & !is.na(obs))],
probs = ecdfHindcast(frc[rain]), na.rm = TRUE, type = 4)
}
}
if (length(drizzle) > 0){
# drizzle part is a seperate part. it use the ecdf of frc (larger than minHindcastPreci) to
# biascorrect the original drizzle part
frc[drizzle] <- quantile(frc[which(frc > min(hindcast[which(hindcast > minHindcastPreci)], na.rm = TRUE) &
!is.na(frc))], probs = ecdfFrc(frc[drizzle]), na.rm = TRUE,
type = 4)
}
frc[noRain] <- 0
} else {
# in this condition minHindcastPreci is the max of hindcast, so all hindcast <= minHindcastPreci
# And frc distribution is used then.
noRain <- which(frc <= minHindcastPreci & !is.na(frc))
rain <- which(frc > minHindcastPreci & !is.na(frc))
if (length(rain) > 0) {
ecdfFrc <- ecdf(frc[rain])
frc[rain] <- quantile(obs[which(obs > prThreshold & !is.na(obs))], probs = ecdfFrc(frc[rain]),
na.rm = TRUE, type = 4)
}
frc[noRain]<-0
}
}
}
} else if (method == 'gqm') {
# this condition I don't know why there should be some value hindcast <= threshold
if (any(hindcast <= prThreshold)) {
ind <- which(obs > prThreshold & !is.na(obs))
obsGamma <- fitdistr(obs[ind],"gamma")
ind <- which(hindcast > 0 & !is.na(hindcast))
hindcastGamma <- fitdistr(hindcast[ind],"gamma")
rain <- which(frc > minHindcastPreci & !is.na(frc))
noRain <- which(frc <= minHindcastPreci & !is.na(frc))
probF <- pgamma(frc[rain], hindcastGamma$estimate[1], rate = hindcastGamma$estimate[2])
frc[rain] <- qgamma(probF,obsGamma$estimate[1], rate = obsGamma$estimate[2])
frc[noRain] <- 0
}
}
return(frc)
}
debug(biasCorrect_core)
frc_new <- biasCorrect(frc, hindcast, obs, input = 'TS', preci = T, prThreshold = 0)
lowerIndex
minHindcastPreci
lowerIndex
minIndex
hindcast_sorted[1:minIndex]
hindcast_sorted[1:1]
hindcast_sorted[1:2]
hindcast_sorted[3:1]
hindcast_sorted[0]
hindcast_sorted[1:0]
hindcast_sorted
devtools::document()
devtools::check()
devtools::build()
data(testdl)
a <- testdl[[1]]
# Choose example from "1994-2-4" to "1996-1-4"
debug(getHisEnsem)
library(hyfo)
debug(getHisEnsem)
b <- getHisEnsem(a, example = c('1994-2-4', '1996-1-4'))
N
str(b)
b <- getHisEnsem(a, example = c('1994-2-4', '1996-1-4'))
data_output
str(data_output)
str(data_output[, -1])
str(data_output[, -2])
